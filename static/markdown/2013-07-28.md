<!---title:Hbase伪分布搭建与应用测试-->
<!---keywords:Hbase,伪分布,hadoop配置,搭建与应用测试-->


速度写下环境搭建第二步，主要是hadoop配置，hbase配置，然后zookeeper看个人需要；最后要做的就是做实例测试。

hadoop配置：
1. apache站点http://www.apache.org/dyn/closer.cgi/hadoop/common/下载hadoop你喜欢的版本
2.解压hadoop-1.2.0.tar.gz，移到个人喜欢的路径，如我的 /usr/local/hadoop
3.更改conf下的配置文件（所列的，都放到configuration里面）

    hdfs-site.xml
     <property>
      <name>dfs.name.dir</name>
      <value>/home/paopao/Data/softdata/hadoop/_hadoop/name</value>
     </property>

     <property>
      <name>dfs.data.dir</name>
      <value>/home/paopao/Data/softdata/hadoop/_hadoop/data</value>
     </property>

     <property>
      <name>dfs.replication</name>
      <value>1</value>
     </property>

    mapred-site.xml
        <property>
            <name>mapred.job.tracker</name>
            <value>localhost:9001</value>
        </property>

    hadoop-env.sh
     export JAVA_HOME=/usr/local/java

    core-site.xml
        <property>
         <name>fs.default.name</name>
         <value>hdfs://localhost:9000</value>
        </property>

        <property>
            <name>hadoop.tmp.dir</name>
            <value>/home/paopao/Data/softdata/hadoop/tmp</value>
        </property>
4.格式化hadoop，准备开始体验hadoop

    root@paopao-K55VD:/usr/local/hadoop# ./bin/hadoop namenode -format
5.启动hadoop，检查启动是否成功

    root@paopao-K55VD:/usr/local/hadoop# ./bin/start-all.sh
    root@paopao-K55VD:/usr/local/hadoop# jps|cut -d' ' -f2|sort
    DataNode
    NameNode
    JobTracker
    Jps
    TaskTracker
    SecondaryNameNode
如果是为以上输出6个java进程，那么，恭喜你，成功了。否则就要查看logs下的日志了。
当然，想查看dfs使用情况：

    root@paopao-K55VD:/usr/local/hadoop# ./bin/hadoop dfsadmin -report
    Safe mode is ON
    Configured Capacity: 0 (0 KB)
    Present Capacity: 0 (0 KB)
    DFS Remaining: 0 (0 KB)
    DFS Used: 0 (0 KB)
    DFS Used%: �%
    Under replicated blocks: 0
    Blocks with corrupt replicas: 0
    Missing blocks: 0
    
    -------------------------------------------------
    Datanodes available: 0 (0 total, 0 dead)

有相应的界面查看： 
http://localhost:50070/dfshealth.jsp
http://localhost:50030/jobtracker.jsp

hbase配置：
1.conf下文件的配置

    hbase－site.xml
    <property>
      <name>hbase.rootdir</name>
         <value>hdfs://localhost:9000/hbase</value>
    </property>

    <property>
      <name>hbase.cluster.distributed</name>
      <value>true</value>
    </property>

    hbase-env.sh
    export JAVA_HOME=/usr/local/java/
    export HBASE_CLASSPATH=/usr/local/hadoop/conf

2.启动hbase，检查启动是否成功

    root@paopao-K55VD:/usr/local/hbase# ./bin/start-hbase.sh 
    root@paopao-K55VD:/usr/local/hbase# jps|cut -d' ' -f2|sort
    DataNode
    HMaster
    HQuorumPeer
    HRegionServer
    JobTracker
    Jps
    NameNode
    SecondaryNameNode
    TaskTracker
如hadoop一样，jps的输出就知道启动是否成功了
hbase管理界面：http://localhost:60010/master-status
zookeeper管理界面：http://localhost:60010/zk.jsp
3.hbase命令行体验：

    root@paopao-K55VD:/usr/local/hbase# ./bin/hbase shell
    HBase Shell; enter 'help<RETURN>' for list of supported commands.
    Type "exit<RETURN>" to leave the HBase Shell
    Version 0.94.8, r1485407, Wed May 22 20:53:13 UTC 2013

    hbase(main):001:0> create 'love','info'
    0 row(s) in 1.7010 seconds
    hbase(main):003:0> put 'love','paopao family','info:girl','my wife'
    0 row(s) in 0.0620 seconds
    hbase(main):011:0> put 'love','paopao family','info:boy','me'
    0 row(s) in 0.0100 seconds
    hbase(main):012:0> get 'love','paopao family'
    COLUMN                                CELL                                                                                                      
     info:boy                             timestamp=1374370913195, value=me 
     info:girl                            timestamp=1374370740760, value=my wife
     2 row(s) in 0.0210 seconds

自行实现数据库操作基类：
    package BeeBase;

    import java.io.IOException;
    import java.util.ArrayList;
    import java.util.List;

    import javax.ws.rs.GET;
    import javax.ws.rs.core.NewCookie;
    import javax.xml.crypto.dsig.keyinfo.KeyValue;

    import org.apache.hadoop.conf.Configuration;
    import org.apache.hadoop.hbase.HBaseConfiguration;
    import org.apache.hadoop.hbase.client.Delete;
    import org.apache.hadoop.hbase.client.Get;
    import org.apache.hadoop.hbase.client.HTable;
    import org.apache.hadoop.hbase.client.Put;
    import org.apache.hadoop.hbase.client.Result;
    import org.apache.hadoop.hbase.util.Bytes;


    public class BHbase {
        // 连接配置
        public static Configuration conf = null;
        
        // 数据库
        public static HTable hTable = null;
        

        public BHbase(String table) {
            this.conf = HBaseConfiguration.create();
            conf.set("hbase.zookeeper.quorum", "localhost");
            try {
                this.hTable = new HTable(conf, table);
            } catch (IOException e) {
                e.printStackTrace();
            }
        }

       
        public void addRecord(String key, String family, String qualifier, String value) {
            Put put = new Put(Bytes.toBytes(key));
            put.add(Bytes.toBytes(family), Bytes.toBytes(qualifier), Bytes.toBytes(value));
            try {
                this.hTable.put(put);
            } catch (IOException e) {
                e.printStackTrace();
            }
        }

       
        public void removeRecord(String key) {
            Delete del = new Delete(key.getBytes());
            try {
                this.hTable.delete(del);
            } catch (IOException e) {
                e.printStackTrace();
            }
            
        }

       
        public Result getRecord(String key) {
            Result rs = null;
            Get get = new Get(Bytes.toBytes(key));
            try {
                rs = this.hTable.get(get);
            } catch (IOException e) {
                e.printStackTrace();
            }
            return rs;
        }

    }


    UnitTest实例：
    package BeeBase;

    import static org.junit.Assert.*;

    import java.util.ArrayList;
    import java.util.List;

    import org.apache.hadoop.hbase.client.Result;
    import org.apache.hadoop.hbase.util.Bytes;
    import org.junit.Test;

    import BeeBase.BHbase;

    public class BHbaseTest {
        public static BHbase bHbaseTest = null;

        public void testBHbase() {

        }

        @Test
        public void testString() {
            List list = new ArrayList();
        }
        @Test
        public void testAddRecord() {
            BHbase bHbaseTest = new BHbase("love");
            bHbaseTest.addRecord("test", "info", "mather", "wu\'s mather");
            this.printResult("love", "test");
            bHbaseTest.addRecord("test", "info", "mather", "wu\'s father");
            this.printResult("love", "test");
        }

        @Test
        public void removeRecord() {
            BHbase bHbaseTest = new BHbase("love");
            bHbaseTest.removeRecord("test");
            this.printResult("love", "test");
        }
        
        public static void printResult(String table, String key) {
            BHbase bHbaseTest = new BHbase(table);
            Result rs = bHbaseTest.getRecord(key);
            System.out.println("======s======");
            for(org.apache.hadoop.hbase.KeyValue kv : rs.raw()) {
                byte[] family = kv.getValue();
                System.out.println(Bytes.toString(family));
            }
            System.out.println("======e======");
        }
        
    }